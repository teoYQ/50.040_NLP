{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o64A6_3JBwD-"
   },
   "source": [
    "# 50.040 Natural Language Processing (Summer 2020) Homework 2\n",
    "\n",
    "**Due**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W4GVrtRTBwED"
   },
   "source": [
    "\n",
    "### STUDNET ID:\n",
    "\n",
    "### Name:\n",
    "\n",
    "### Students with whom you have discussed (if any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Isf9KyrxBwEG"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "from nltk.tree import Tree\n",
    "from nltk import Nonterminal\n",
    "from nltk.corpus import LazyCorpusLoader, BracketParseCorpusReader\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ASQNd3YQBwER"
   },
   "outputs": [],
   "source": [
    "st = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "eBrBFo6RBwEc",
    "outputId": "d1291065-077b-4a61-bd74-49f2af9ad96f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to C:\\Users\\Student-\n",
      "[nltk_data]     TeoYongQuan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\treebank.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2qn4Jjx-BwEj"
   },
   "outputs": [],
   "source": [
    "def set_leave_lower(tree_string):\n",
    "    if isinstance(tree_string, Tree):\n",
    "        tree = tree_string\n",
    "    else:\n",
    "        tree = Tree.fromstring(tree_string)\n",
    "    for idx, _ in enumerate(tree.leaves()):\n",
    "        tree_location = tree.leaf_treeposition(idx)\n",
    "        non_terminal = tree[tree_location[:-1]]\n",
    "        non_terminal[0] = non_terminal[0].lower()\n",
    "    return tree\n",
    "\n",
    "def get_train_test_data():\n",
    "    '''\n",
    "    Load training and test set from nltk corpora\n",
    "    '''\n",
    "    train_num = 3900\n",
    "    test_index = range(10)\n",
    "    treebank = LazyCorpusLoader('treebank/combined', BracketParseCorpusReader, r'wsj_.*\\.mrg')\n",
    "    cnf_train = treebank.parsed_sents()[:train_num]\n",
    "    cnf_test = [treebank.parsed_sents()[i+train_num] for i in test_index]\n",
    "    #Convert to Chomsky norm form, remove auxiliary labels\n",
    "    cnf_train = [convert2cnf(t) for t in cnf_train]\n",
    "    cnf_test = [convert2cnf(t) for t in cnf_test]\n",
    "    return cnf_train, cnf_test\n",
    "def convert2cnf(original_tree):\n",
    "    '''\n",
    "    Chomsky norm form\n",
    "    '''\n",
    "    tree = copy.deepcopy(original_tree)\n",
    "    \n",
    "    #Remove cases like NP->DT, VP->NP\n",
    "    tree.collapse_unary(collapsePOS=True, collapseRoot=True)\n",
    "    #Convert to Chomsky\n",
    "    tree.chomsky_normal_form()\n",
    "    \n",
    "    tree = set_leave_lower(tree)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8YRqL0EBwEr"
   },
   "outputs": [],
   "source": [
    "### GET TRAIN/TEST DATA\n",
    "cnf_train, cnf_test = get_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "33EP69hlBwEz",
    "outputId": "95462d87-5895-438c-fbaf-1aabe659da15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP pierre) (NNP vinken))\n",
      "    (NP-SBJ|<,-ADJP-,>\n",
      "      (, ,)\n",
      "      (NP-SBJ|<ADJP-,>\n",
      "        (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
      "        (, ,))))\n",
      "  (S|<VP-.>\n",
      "    (VP\n",
      "      (MD will)\n",
      "      (VP\n",
      "        (VB join)\n",
      "        (VP|<NP-PP-CLR-NP-TMP>\n",
      "          (NP (DT the) (NN board))\n",
      "          (VP|<PP-CLR-NP-TMP>\n",
      "            (PP-CLR\n",
      "              (IN as)\n",
      "              (NP\n",
      "                (DT a)\n",
      "                (NP|<JJ-NN> (JJ nonexecutive) (NN director))))\n",
      "            (NP-TMP (NNP nov.) (CD 29))))))\n",
      "    (. .)))\n"
     ]
    }
   ],
   "source": [
    "cnf_train[0].pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsI9vFCXBwE9"
   },
   "source": [
    "## Question 1\n",
    "\n",
    "To  better  understand  PCFG,  let’s  consider  the  first  parse  tree  in  the training data “cnf_train” as an example.  Run the code we have provided for you and then writedown the roles of.productions(), .rhs(), .lhs(), .leaves()in the ipynb notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "ahq_5ETjBwE-",
    "outputId": "f7967987-dc43-48d9-acc5-f99dfe904f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S -> NP-SBJ S|<VP-.>, NP-SBJ -> NP NP-SBJ|<,-ADJP-,>, NP -> NNP NNP, NNP -> 'pierre', NNP -> 'vinken', NP-SBJ|<,-ADJP-,> -> , NP-SBJ|<ADJP-,>, , -> ',', NP-SBJ|<ADJP-,> -> ADJP ,, ADJP -> NP JJ, NP -> CD NNS, CD -> '61', NNS -> 'years', JJ -> 'old', , -> ',', S|<VP-.> -> VP ., VP -> MD VP, MD -> 'will', VP -> VB VP|<NP-PP-CLR-NP-TMP>, VB -> 'join', VP|<NP-PP-CLR-NP-TMP> -> NP VP|<PP-CLR-NP-TMP>, NP -> DT NN, DT -> 'the', NN -> 'board', VP|<PP-CLR-NP-TMP> -> PP-CLR NP-TMP, PP-CLR -> IN NP, IN -> 'as', NP -> DT NP|<JJ-NN>, DT -> 'a', NP|<JJ-NN> -> JJ NN, JJ -> 'nonexecutive', NN -> 'director', NP-TMP -> NNP CD, NNP -> 'nov.', CD -> '29', . -> '.'] <class 'nltk.grammar.Production'>\n"
     ]
    }
   ],
   "source": [
    "rules = cnf_train[0].productions()\n",
    "print(rules, type(rules[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YwrgxKD_BwFK",
    "outputId": "23227f4a-6720-4b77-ab68-682ab6921745"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((NP-SBJ, S|<VP-.>), nltk.grammar.Nonterminal)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[0].rhs(), type(rules[0].rhs()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9tWLd6cgBwFR",
    "outputId": "f0cb2185-a7ab-4ac9-d708-58b6cb44677c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('61',), str)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[10].rhs(), type(rules[10].rhs()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YMN4Tr-gBwFY",
    "outputId": "0de74fc9-c646-4132-ceea-7a2393e82a4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(S, nltk.grammar.Nonterminal)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[0].lhs(), type(rules[0].lhs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "4MEA3lzPBwFh",
    "outputId": "e8878f29-3404-4e49-e877-535a82fd4027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pierre', 'vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', '29', '.']\n"
     ]
    }
   ],
   "source": [
    "print(cnf_train[0].leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m1rmTrkiBwFr"
   },
   "source": [
    "ANSWER HERE\n",
    "- productions(): Rykes tgat firn tge tree\n",
    "- rhs(): right side childrens in the production rule\n",
    "- lhs(): parents in the production rule\n",
    "- leaves(): a list of string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wx7d8sQFBwFt"
   },
   "source": [
    "## Question 2\n",
    "To count the number of unique rules, nonterminals and terminals, pleaseimplement functions **collect_rules, collect_nonterminals, collect_terminals**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGgeMVXCBwFv"
   },
   "outputs": [],
   "source": [
    "def collect_rules(train_data):\n",
    "    '''\n",
    "    Collect the rules that appear in data.\n",
    "    params:\n",
    "        train_data: list[Tree] --- list of Tree objects\n",
    "    return:\n",
    "        rules: list[nltk.grammar.Production] --- list of rules (Production objects)\n",
    "        rules_counts: Counter object --- a dictionary that maps one rule (nltk.Nonterminal) to its number of \n",
    "                                         occurences (int) in train data.\n",
    "    '''\n",
    "    rules = list()\n",
    "    rules_counts = Counter()\n",
    "    ### YOUR CODE HERE (~ 2 lines)\n",
    "    for i in train_data:\n",
    "      for j in i.productions():\n",
    "        rules.append(j)\n",
    "    rule_counts = Counter(rules)\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    return rules, rule_counts\n",
    "\n",
    "def collect_nonterminals(rules):\n",
    "    '''\n",
    "    collect nonterminals that appear in the rules\n",
    "    params:\n",
    "        rules: list[nltk.grammar.Production] --- list of rules (Production objects)\n",
    "    return:\n",
    "        nonterminals: set(nltk.Nonterminal) --- set of nonterminals \n",
    "    '''\n",
    "    nonterminals = list()\n",
    "    ### YOUR CODE HERE (at least one line)\n",
    "    for rule in rules:\n",
    "      lhs = rule.lhs()\n",
    "      rhs = rule.rhs()\n",
    "      #for nt in lhs:\n",
    "      if type(lhs) == nltk.Nonterminal:\n",
    "        nonterminals.append(lhs)\n",
    "      #for nt in rhs:\n",
    "      if type(rhs) == nltk.Nonterminal:\n",
    "        nonterminals.append(rhs)\n",
    "    ### END OF YOUR CODE\n",
    "    return set(nonterminals)\n",
    "\n",
    "def collect_terminals(rules):\n",
    "    '''\n",
    "    collect terminals that appear in the rules\n",
    "    params:\n",
    "        rules: list[nltk.grammar.Production] --- list of rules (Production objects)\n",
    "    return:\n",
    "        terminals: set of strings --- set of terminals    \n",
    "    '''\n",
    "    terminals = list()\n",
    "    ### YOUR CODE HERE (at least one line)\n",
    "    for rule in rules:\n",
    "      for terminal in rule.rhs():\n",
    "        if type(terminal) == str:\n",
    "          terminals.append(terminal)\n",
    "    ### END OF YOUR CODE\n",
    "\n",
    "    return set(terminals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MDeV9H4GBwF6"
   },
   "outputs": [],
   "source": [
    "train_rules, train_rules_counts = collect_rules(cnf_train)\n",
    "nonterminals = collect_nonterminals(train_rules)\n",
    "terminals = collect_terminals(train_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-wuf2jEdBwGB",
    "outputId": "dd52ed16-064f-42f6-e547-c4840b3271c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196646, 31656, 11367, 7869)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CORRECT ANSWER (19xxxx, 3xxxx, 1xxxx, 7xxx)\n",
    "len(train_rules), len(set(train_rules)), len(terminals), len(nonterminals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dqHAHh83BwGJ",
    "outputId": "9b65b4ea-0999-4c98-b7da-a50dfaf8cdf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(, -> ',', 4876), (DT -> 'the', 4726), (. -> '.', 3814), (PP -> IN NP, 3273), (S|<VP-.> -> VP ., 3003)]\n"
     ]
    }
   ],
   "source": [
    "print(train_rules_counts.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OrmOjAs3BwGT"
   },
   "source": [
    "## Question 3\n",
    "Implement the function **build_pcfg** which builds a dictionary that stores theterminal rules and nonterminal rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "3pyY8igsBwGV",
    "outputId": "fa688e7f-2242-4e4b-89ca-b42437e83d2b"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-16726ef159f6>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    rules_dict[]\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def build_pcfg(rules_counts):\n",
    "    '''\n",
    "    Build a dictionary that stores the terminal rules and nonterminal rules.\n",
    "    param:\n",
    "        rules_counts: Counter object --- a dictionary that maps one rule to its number of occurences in train data.\n",
    "    return:\n",
    "        rules_dict: dict(dict(dict)) --- a dictionary has a form like:\n",
    "                    rules_dict = {'terminals':{'NP':{'the':1000,'an':500}, 'ADJ':{'nice':500,'good':100}},\n",
    "                                  'nonterminals':{'S':{'NP@VP':1000},'NP':{'NP@NP':540}}}\n",
    "    When building \"rules_dict\", you need to use \"lhs()\", \"rhs()\" funtion and convert Nonterminal to str.\n",
    "    All the keys in the dictionary are of type str.\n",
    "    '@' is used as a special symbol to split left and right nonterminal strings.\n",
    "    '''\n",
    "    \n",
    "    rules_dict = dict()\n",
    "    ### rules_dict['terminals'] contains rules like \"NP->'the'\"\n",
    "    ### rules_dict['nonterminals'] contains rules like \"S->NP@VP\"\n",
    "    rules_dict['terminals'] = defaultdict(dict)\n",
    "    rules_dict['nonterminals'] = defaultdict(dict)\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    i=0\n",
    "    for rule,count in rules_counts.items():\n",
    "      if type(rule.rhs()[0]) == str:\n",
    "        #this is a terminal\n",
    "        rules_dict[\"terminals\"][str(rule.lhs())].get\n",
    "      #print(rule,count)\n",
    "     # print(\"right \",rule.rhs(), \" type \", type(rule.rhs()[0]))\n",
    "     # print(rule.rhs()[0])\n",
    "      if type(rule.lhs())==str:\n",
    "        print(\"left \",rule.lhs(),\" type \", type(rule.lhs()))\n",
    "     # print(\"testing \",\"@\".join(list(str(o) for o in rule.rhs())))\n",
    "      #for i in range(2):\n",
    "        #if i == 1: #do rhs\n",
    "         # if type(rule.rhs()[0]) != str: #means not terminal\n",
    "          #  pass\n",
    "      #i+= 1\n",
    "      #if i > 100:\n",
    "       # break\n",
    "      \n",
    "    ### END OF YOUR CODE\n",
    "    return rules_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZaHXJP7gBwGb"
   },
   "outputs": [],
   "source": [
    "train_rules_dict = build_pcfg(train_rules_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oyzE6I_-BwGr"
   },
   "source": [
    "## Question 4\n",
    "Estimate the probability of rule $NP\\rightarrow NNP@NNP$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ky-uHUQXBwGt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f8x1bPkmBwG1"
   },
   "source": [
    "## Question 5\n",
    "Find the terminal symbols in ''cnf_test[0]'' that never appeared in the PCFG we built. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OViT6-mIBwG3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Jre-4bvBwG_"
   },
   "source": [
    "## Question 6\n",
    "We can use smoothing techniques to handle these cases. A simple smoothing method is as follows. We first create a new \"unknown\" terminal symbol $unk$.\n",
    "\n",
    "Next, for each original non-terminal symbol $A\\in N$, we add one new rule $A \\rightarrow unk$ to the original PCFG.\n",
    "\n",
    "The smoothed probabilities for all rules can then be estimated as:\n",
    "$$q_{smooth}(A \\rightarrow \\beta) = \\frac {count(A \\rightarrow \\beta)}{count(A)+1}$$\n",
    "$$q_{smooth}(A \\rightarrow unk) = \\frac {1}{count(A)+1}$$\n",
    "where $|V|$ is the count of unique terminal symbols.\n",
    "\n",
    "\n",
    "Implement the function **smooth_rules_prob** which returns the smoothed rule probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PA5hSj0MBwHB"
   },
   "outputs": [],
   "source": [
    "def smooth_rules_prob(rules_counts):\n",
    "    '''\n",
    "    params:\n",
    "        rules_counts: dict(dict(dict)) --- a dictionary has a form like:\n",
    "                      rules_counts = {'terminals':{'NP':{'the':1000,'an':500}, 'ADJ':{'nice':500,'good':100}},\n",
    "                                      'nonterminals':{'S':{'NP@VP':1000},'NP':{'NP@NP':540}}}\n",
    "    \n",
    "    return:\n",
    "        rules_prob: dict(dict(dict)) --- a dictionary that has a form like:\n",
    "                               rules_prob = {'terminals':{'NP':{'the':0.6,'an':0.3, '<unk>':0.1},\n",
    "                                                          'ADJ':{'nice':0.6,'good':0.3,'<unk>':0.1},\n",
    "                                                          'S':{'<unk>':0.01}}}\n",
    "                                             'nonterminals':{'S':{'NP@VP':0.99}}\n",
    "    '''\n",
    "    rules_prob = copy.deepcopy(rules_counts)\n",
    "    unk = '<unk>'\n",
    "    ### Hint: don't forget to consider nonterminal symbols that don't appear in rules_counts['terminals'].keys()\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END OF YOUR CODE\n",
    "    return rules_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LfOKBjNMBwHM"
   },
   "outputs": [],
   "source": [
    "s_rules_prob = smooth_rules_prob(train_rules_dict)\n",
    "terminals.add('<unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AsjI5iolBwHT"
   },
   "outputs": [],
   "source": [
    "print(s_rules_prob['nonterminals']['S']['NP-SBJ@S|<VP-.>'])\n",
    "print(s_rules_prob['nonterminals']['S']['NP-SBJ-1@S|<VP-.>'])\n",
    "print(s_rules_prob['nonterminals']['NP']['NNP@NNP'])\n",
    "print(s_rules_prob['terminals']['NP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xnWXKQQuBwHc"
   },
   "outputs": [],
   "source": [
    "len(terminals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FzS8CuP6BwHk"
   },
   "source": [
    "## CKY Algorithm\n",
    "\n",
    "Similar to the Viterbi algorithm, the CKY algorithm is a dynamic-programming algorithm. Given a PCFG $G=(N, \\ \\Sigma, \\ S, \\ R, \\ q)$, we can use the CKY algorithm described in class to find the highest scoring parse tree for a sentence. \n",
    "\n",
    "First, let us complete the *CKY* function from scratch using only Python built-in functions and the Numpy package. \n",
    "\n",
    "The output should be two dictionaries $\\pi$ and $bp$, which store the optimal probability and backpointer information respectively.\n",
    "\n",
    "Given a sentence $w_0, w_1, ...,w_{n-1}$,  $\\pi(i, k, X)$, $bp(i, k, X)$ refer to the highest score and backpointer for the (partial) parse tree that has the root X (a non-terminal symbol) and covers the word span $w_i, ..., w_{k-1}$, where $0 \\le i < k \\le n$. Note that a backpointer includes both the best grammar rule chosen and the best split point.\n",
    "![tree](imgs/parse_tree.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BWp_QKhBwHm"
   },
   "source": [
    "## Question 7\n",
    "Implement **CKY** function and run the test code to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GNbGgxsBwHq"
   },
   "outputs": [],
   "source": [
    "def CKY(sent, rules_prob):\n",
    "    '''\n",
    "    params:\n",
    "        sent: list[str] --- a list of strings\n",
    "        rules_prob: dict(dict(dict)) --- a dictionary that has a form like:\n",
    "                                           rules_prob = {'terminals':{'NP':{'the':0.6,'an':0.3, '<unk>':0.1},\n",
    "                                                                      'ADJ':{'nice':0.6,'good':0.3,'<unk>':0.1},\n",
    "                                                                      'S':{'<unk>':0.01}}}\n",
    "                                                         'nonterminals':{'S':{'NP@VP':0.99}}\n",
    "    return:\n",
    "        score: dict() --- score[(i,i+span)][root] represents the highest score for the parse (sub)tree that has the root \"root\"\n",
    "                          across words w_i, w_{i+1},..., w_{i+span-1}.\n",
    "        back: dict() --- back[(i,i+span)][root] = (split , left_child, right_child); split: int; \n",
    "                         left_child: str; right_child: str. \n",
    "    '''\n",
    "    score = defaultdict(dict)\n",
    "    back = defaultdict(dict)\n",
    "    sent_len = len(sent)\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END OF YOUR CODE                  \n",
    "    return score, back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUabi0JwBwH1"
   },
   "outputs": [],
   "source": [
    "sent = cnf_train[0].leaves()\n",
    "score, back = CKY(sent, s_rules_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g07-P0eSBwH7"
   },
   "outputs": [],
   "source": [
    "score[(0, len(sent))]['S']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GKtzvtpFBwID"
   },
   "source": [
    "## Question 8\n",
    "Implement **build_tree** function according to algorithm 2 to reconstruct theparse tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JhyPpJUBwIE"
   },
   "outputs": [],
   "source": [
    "def build_tree(back, root):\n",
    "    '''\n",
    "    Build the tree recursively.\n",
    "    params:\n",
    "        back: dict() --- back[(i,i+span)][X] = (split , left_child, right_child); split:int; left_child: str; right_child: str.\n",
    "        root: tuple() --- (begin, end, nonterminal_symbol), e.g., (0, 10, 'S\n",
    "    return:\n",
    "        tree: nltk.tree.Tree\n",
    "    '''\n",
    "    begin = root[0]\n",
    "    end = root[1]\n",
    "    root_label = root[2]\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    ### END OF YOUR CODE \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pf4rrfFkBwIJ"
   },
   "outputs": [],
   "source": [
    "build_tree(back, (0, len(sent), 'S'), nonterminals).pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BREjaTD0BwIY"
   },
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ylVH27EyBwIa"
   },
   "outputs": [],
   "source": [
    "def set_leave_index(tree):\n",
    "    '''\n",
    "    Label the leaves of the tree with indexes\n",
    "    Arg:\n",
    "        tree: original tree, nltk.tree.Tree\n",
    "    Return:\n",
    "        tree: preprocessed tree, nltk.tree.Tree\n",
    "    '''\n",
    "    for idx, _ in enumerate(tree.leaves()):\n",
    "        tree_location = tree.leaf_treeposition(idx)\n",
    "        non_terminal = tree[tree_location[:-1]]\n",
    "        non_terminal[0] = non_terminal[0] + \"_\" + str(idx)\n",
    "    return tree\n",
    "\n",
    "def get_nonterminal_bracket(tree):\n",
    "    '''\n",
    "    Obtain the constituent brackets of a tree\n",
    "    Arg:\n",
    "        tree: tree, nltk.tree.Tree\n",
    "    Return:\n",
    "        nonterminal_brackets: constituent brackets, set\n",
    "    '''\n",
    "    nonterminal_brackets = set()\n",
    "    for tr in tree.subtrees():\n",
    "        label = tr.label()\n",
    "        #print(tr.leaves())\n",
    "        if len(tr.leaves()) == 0:\n",
    "            continue\n",
    "        start = tr.leaves()[0].split('_')[-1]\n",
    "        end = tr.leaves()[-1].split('_')[-1]\n",
    "        if start != end:\n",
    "            nonterminal_brackets.add(label+'-('+start+':'+end+')')\n",
    "    return nonterminal_brackets\n",
    "\n",
    "def word2lower(w, terminals):\n",
    "    '''\n",
    "    Map an unknow word to \"unk\"\n",
    "    '''\n",
    "    return w.lower() if w in terminals else '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCJhoQjQBwIl"
   },
   "outputs": [],
   "source": [
    "correct_count = 0\n",
    "pred_count = 0\n",
    "gold_count = 0\n",
    "for i, t in enumerate(cnf_test):\n",
    "    #Protect the original tree \n",
    "    t = copy.deepcopy(t)\n",
    "    sent = t.leaves()  \n",
    "    #Map the unknow words to \"unk\"\n",
    "    sent = [word2lower(w.lower(), terminals) for w in sent]\n",
    "    \n",
    "    #CKY algorithm\n",
    "    score, back = CKY(sent, s_rules_prob)\n",
    "    candidate_tree = build_tree(back, (0, len(sent), 'S'), nonterminals)\n",
    "    \n",
    "    #Extract constituents from the gold tree and predicted tree\n",
    "    pred_tree = set_leave_index(candidate_tree)\n",
    "    pred_brackets = get_nonterminal_bracket(pred_tree)\n",
    "    \n",
    "    #Count correct constituents\n",
    "    pred_count += len(pred_brackets)\n",
    "    gold_tree = set_leave_index(t)\n",
    "    gold_brackets = get_nonterminal_bracket(gold_tree)\n",
    "    gold_count += len(gold_brackets)\n",
    "    current_correct_num = len(pred_brackets.intersection(gold_brackets))\n",
    "    correct_count += current_correct_num\n",
    "    \n",
    "    print('#'*20)\n",
    "    print('Test Tree:', i+1)\n",
    "    print('Constituent number in the predicted tree:', len(pred_brackets))\n",
    "    print('Constituent number in the gold tree:', len(gold_brackets))\n",
    "    print('Correct constituent number:', current_correct_num)\n",
    "\n",
    "recall = correct_count/gold_count\n",
    "precision = correct_count/pred_count\n",
    "f1 = 2*recall*precision/(recall+precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6_XBc6-BwIy"
   },
   "outputs": [],
   "source": [
    "print('Overall precision: {:.3f}, recall: {:.3f}, f1: {:.3f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcVa_8gtBwJD"
   },
   "outputs": [],
   "source": [
    "print('Overall precision: {:.3f}, recall: {:.3f}, f1: {:.3f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6MSULjTYBwJI"
   },
   "outputs": [],
   "source": [
    "et=time.time()\n",
    "print(et - st)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "homework2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
