{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o64A6_3JBwD-"
   },
   "source": [
    "# 50.040 Natural Language Processing (Summer 2020) Homework 2\n",
    "\n",
    "**Due**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W4GVrtRTBwED"
   },
   "source": [
    "\n",
    "### STUDNET ID:\n",
    "\n",
    "### Name:\n",
    "\n",
    "### Students with whom you have discussed (if any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Isf9KyrxBwEG"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from collections import Counter\n",
    "from nltk.tree import Tree\n",
    "from nltk import Nonterminal\n",
    "from nltk.corpus import LazyCorpusLoader, BracketParseCorpusReader\n",
    "from collections import defaultdict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ASQNd3YQBwER"
   },
   "outputs": [],
   "source": [
    "st = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "eBrBFo6RBwEc",
    "outputId": "d1291065-077b-4a61-bd74-49f2af9ad96f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to C:\\Users\\Student-\n",
      "[nltk_data]     TeoYongQuan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2qn4Jjx-BwEj"
   },
   "outputs": [],
   "source": [
    "def set_leave_lower(tree_string):\n",
    "    if isinstance(tree_string, Tree):\n",
    "        tree = tree_string\n",
    "    else:\n",
    "        tree = Tree.fromstring(tree_string)\n",
    "    for idx, _ in enumerate(tree.leaves()):\n",
    "        tree_location = tree.leaf_treeposition(idx)\n",
    "        non_terminal = tree[tree_location[:-1]]\n",
    "        non_terminal[0] = non_terminal[0].lower()\n",
    "    return tree\n",
    "\n",
    "def get_train_test_data():\n",
    "    '''\n",
    "    Load training and test set from nltk corpora\n",
    "    '''\n",
    "    train_num = 3900\n",
    "    test_index = range(10)\n",
    "    treebank = LazyCorpusLoader('treebank/combined', BracketParseCorpusReader, r'wsj_.*\\.mrg')\n",
    "    cnf_train = treebank.parsed_sents()[:train_num]\n",
    "    cnf_test = [treebank.parsed_sents()[i+train_num] for i in test_index]\n",
    "    #Convert to Chomsky norm form, remove auxiliary labels\n",
    "    cnf_train = [convert2cnf(t) for t in cnf_train]\n",
    "    cnf_test = [convert2cnf(t) for t in cnf_test]\n",
    "    return cnf_train, cnf_test\n",
    "def convert2cnf(original_tree):\n",
    "    '''\n",
    "    Chomsky norm form\n",
    "    '''\n",
    "    tree = copy.deepcopy(original_tree)\n",
    "    \n",
    "    #Remove cases like NP->DT, VP->NP\n",
    "    tree.collapse_unary(collapsePOS=True, collapseRoot=True)\n",
    "    #Convert to Chomsky\n",
    "    tree.chomsky_normal_form()\n",
    "    \n",
    "    tree = set_leave_lower(tree)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8YRqL0EBwEr"
   },
   "outputs": [],
   "source": [
    "### GET TRAIN/TEST DATA\n",
    "cnf_train, cnf_test = get_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 431
    },
    "colab_type": "code",
    "id": "33EP69hlBwEz",
    "outputId": "95462d87-5895-438c-fbaf-1aabe659da15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP pierre) (NNP vinken))\n",
      "    (NP-SBJ|<,-ADJP-,>\n",
      "      (, ,)\n",
      "      (NP-SBJ|<ADJP-,>\n",
      "        (ADJP (NP (CD 61) (NNS years)) (JJ old))\n",
      "        (, ,))))\n",
      "  (S|<VP-.>\n",
      "    (VP\n",
      "      (MD will)\n",
      "      (VP\n",
      "        (VB join)\n",
      "        (VP|<NP-PP-CLR-NP-TMP>\n",
      "          (NP (DT the) (NN board))\n",
      "          (VP|<PP-CLR-NP-TMP>\n",
      "            (PP-CLR\n",
      "              (IN as)\n",
      "              (NP\n",
      "                (DT a)\n",
      "                (NP|<JJ-NN> (JJ nonexecutive) (NN director))))\n",
      "            (NP-TMP (NNP nov.) (CD 29))))))\n",
      "    (. .)))\n"
     ]
    }
   ],
   "source": [
    "cnf_train[0].pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HsI9vFCXBwE9"
   },
   "source": [
    "## Question 1\n",
    "\n",
    "To  better  understand  PCFG,  let’s  consider  the  first  parse  tree  in  the training data “cnf_train” as an example.  Run the code we have provided for you and then writedown the roles of.productions(), .rhs(), .lhs(), .leaves()in the ipynb notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "ahq_5ETjBwE-",
    "outputId": "f7967987-dc43-48d9-acc5-f99dfe904f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[S -> NP-SBJ S|<VP-.>, NP-SBJ -> NP NP-SBJ|<,-ADJP-,>, NP -> NNP NNP, NNP -> 'pierre', NNP -> 'vinken', NP-SBJ|<,-ADJP-,> -> , NP-SBJ|<ADJP-,>, , -> ',', NP-SBJ|<ADJP-,> -> ADJP ,, ADJP -> NP JJ, NP -> CD NNS, CD -> '61', NNS -> 'years', JJ -> 'old', , -> ',', S|<VP-.> -> VP ., VP -> MD VP, MD -> 'will', VP -> VB VP|<NP-PP-CLR-NP-TMP>, VB -> 'join', VP|<NP-PP-CLR-NP-TMP> -> NP VP|<PP-CLR-NP-TMP>, NP -> DT NN, DT -> 'the', NN -> 'board', VP|<PP-CLR-NP-TMP> -> PP-CLR NP-TMP, PP-CLR -> IN NP, IN -> 'as', NP -> DT NP|<JJ-NN>, DT -> 'a', NP|<JJ-NN> -> JJ NN, JJ -> 'nonexecutive', NN -> 'director', NP-TMP -> NNP CD, NNP -> 'nov.', CD -> '29', . -> '.'] <class 'nltk.grammar.Production'>\n"
     ]
    }
   ],
   "source": [
    "rules = cnf_train[0].productions()\n",
    "print(rules, type(rules[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YwrgxKD_BwFK",
    "outputId": "23227f4a-6720-4b77-ab68-682ab6921745"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((NP-SBJ, S|<VP-.>), nltk.grammar.Nonterminal)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[0].rhs(), type(rules[0].rhs()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9tWLd6cgBwFR",
    "outputId": "f0cb2185-a7ab-4ac9-d708-58b6cb44677c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('61',), str)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[10].rhs(), type(rules[10].rhs()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YMN4Tr-gBwFY",
    "outputId": "0de74fc9-c646-4132-ceea-7a2393e82a4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(S, nltk.grammar.Nonterminal)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules[0].lhs(), type(rules[0].lhs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "4MEA3lzPBwFh",
    "outputId": "e8878f29-3404-4e49-e877-535a82fd4027"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pierre', 'vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'nov.', '29', '.']\n"
     ]
    }
   ],
   "source": [
    "print(cnf_train[0].leaves())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m1rmTrkiBwFr"
   },
   "source": [
    "ANSWER HERE\n",
    "- productions(): Rykes tgat firn tge tree\n",
    "- rhs(): right side childrens in the production rule\n",
    "- lhs(): parents in the production rule\n",
    "- leaves(): a list of string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wx7d8sQFBwFt"
   },
   "source": [
    "## Question 2\n",
    "To count the number of unique rules, nonterminals and terminals, pleaseimplement functions **collect_rules, collect_nonterminals, collect_terminals**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGgeMVXCBwFv"
   },
   "outputs": [],
   "source": [
    "def collect_rules(train_data):\n",
    "    '''\n",
    "    Collect the rules that appear in data.\n",
    "    params:\n",
    "        train_data: list[Tree] --- list of Tree objects\n",
    "    return:\n",
    "        rules: list[nltk.grammar.Production] --- list of rules (Production objects)\n",
    "        rules_counts: Counter object --- a dictionary that maps one rule (nltk.Nonterminal) to its number of \n",
    "                                         occurences (int) in train data.\n",
    "    '''\n",
    "    rules = list()\n",
    "    rules_counts = Counter()\n",
    "    ### YOUR CODE HERE (~ 2 lines)\n",
    "    for i in train_data:\n",
    "      for j in i.productions():\n",
    "        rules.append(j)\n",
    "    rule_counts = Counter(rules)\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    return rules, rule_counts\n",
    "\n",
    "def collect_nonterminals(rules):\n",
    "    '''\n",
    "    collect nonterminals that appear in the rules\n",
    "    params:\n",
    "        rules: list[nltk.grammar.Production] --- list of rules (Production objects)\n",
    "    return:\n",
    "        nonterminals: set(nltk.Nonterminal) --- set of nonterminals \n",
    "    '''\n",
    "    nonterminals = list()\n",
    "    ### YOUR CODE HERE (at least one line)\n",
    "    for rule in rules:\n",
    "      lhs = rule.lhs()\n",
    "      rhs = rule.rhs()\n",
    "      #for nt in lhs:\n",
    "      if type(lhs) == nltk.Nonterminal:\n",
    "        nonterminals.append(lhs)\n",
    "      #for nt in rhs:\n",
    "      if type(rhs) == nltk.Nonterminal:\n",
    "        nonterminals.append(rhs)\n",
    "    ### END OF YOUR CODE\n",
    "    return set(nonterminals)\n",
    "\n",
    "def collect_terminals(rules):\n",
    "    '''\n",
    "    collect terminals that appear in the rules\n",
    "    params:\n",
    "        rules: list[nltk.grammar.Production] --- list of rules (Production objects)\n",
    "    return:\n",
    "        terminals: set of strings --- set of terminals    \n",
    "    '''\n",
    "    terminals = list()\n",
    "    ### YOUR CODE HERE (at least one line)\n",
    "    for rule in rules:\n",
    "      for terminal in rule.rhs():\n",
    "        if type(terminal) == str:\n",
    "          terminals.append(terminal)\n",
    "    ### END OF YOUR CODE\n",
    "\n",
    "    return set(terminals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MDeV9H4GBwF6"
   },
   "outputs": [],
   "source": [
    "train_rules, train_rules_counts = collect_rules(cnf_train)\n",
    "nonterminals = collect_nonterminals(train_rules)\n",
    "terminals = collect_terminals(train_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "-wuf2jEdBwGB",
    "outputId": "dd52ed16-064f-42f6-e547-c4840b3271c2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196646, 31656, 11367, 7869)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CORRECT ANSWER (19xxxx, 3xxxx, 1xxxx, 7xxx)\n",
    "len(train_rules), len(set(train_rules)), len(terminals), len(nonterminals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "dqHAHh83BwGJ",
    "outputId": "9b65b4ea-0999-4c98-b7da-a50dfaf8cdf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(, -> ',', 4876), (DT -> 'the', 4726), (. -> '.', 3814), (PP -> IN NP, 3273), (S|<VP-.> -> VP ., 3003)]\n"
     ]
    }
   ],
   "source": [
    "print(train_rules_counts.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OrmOjAs3BwGT"
   },
   "source": [
    "## Question 3\n",
    "Implement the function **build_pcfg** which builds a dictionary that stores theterminal rules and nonterminal rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "3pyY8igsBwGV",
    "outputId": "fa688e7f-2242-4e4b-89ca-b42437e83d2b"
   },
   "outputs": [],
   "source": [
    "def build_pcfg(rules_counts):\n",
    "    '''\n",
    "    Build a dictionary that stores the terminal rules and nonterminal rules.\n",
    "    param:\n",
    "        rules_counts: Counter object --- a dictionary that maps one rule to its number of occurences in train data.\n",
    "    return:\n",
    "        rules_dict: dict(dict(dict)) --- a dictionary has a form like:\n",
    "                    rules_dict = {'terminals':{'NP':{'the':1000,'an':500}, 'ADJ':{'nice':500,'good':100}},\n",
    "                                  'nonterminals':{'S':{'NP@VP':1000},'NP':{'NP@NP':540}}}\n",
    "    When building \"rules_dict\", you need to use \"lhs()\", \"rhs()\" funtion and convert Nonterminal to str.\n",
    "    All the keys in the dictionary are of type str.\n",
    "    '@' is used as a special symbol to split left and right nonterminal strings.\n",
    "    '''\n",
    "    \n",
    "    rules_dict = dict()\n",
    "    ### rules_dict['terminals'] contains rules like \"NP->'the'\"\n",
    "    ### rules_dict['nonterminals'] contains rules like \"S->NP@VP\"\n",
    "    rules_dict['terminals'] = defaultdict(dict)\n",
    "    rules_dict['nonterminals'] = defaultdict(dict)\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    i=0\n",
    "    for rule,count in rules_counts.items():\n",
    "        \n",
    "        if type(rule.rhs()[0]) == str:\n",
    "        #this is a terminal\n",
    "            #print(str(rule.rhs()))\n",
    "            rules_dict[\"terminals\"][str(rule.lhs())] = rules_dict[\"terminals\"].get(str(rule.lhs()),{}) \n",
    "            rules_dict[\"terminals\"][str(rule.lhs())][str(rule.rhs()[0])] = rules_dict[\"terminals\"][str(rule.lhs())].get(str(rule.rhs()[0]),0) + count\n",
    "        else:\n",
    "            string_right = \"\"\n",
    "            for right in rule.rhs():\n",
    "                string_right += str(right)\n",
    "                string_right += \"@\"\n",
    "            string_right = string_right[:-1]\n",
    "            #if string_right == \"NNP@NNP\":\n",
    "                #print(string_right,str(rule.lhs()))\n",
    "            rules_dict[\"nonterminals\"][str(rule.lhs())] = rules_dict[\"nonterminals\"].get(str(rule.lhs()),{}) \n",
    "            rules_dict[\"nonterminals\"][str(rule.lhs())][string_right] = rules_dict[\"nonterminals\"][str(rule.lhs())].get(string_right,0) + count\n",
    "    ### END OF YOUR CODE\n",
    "    return rules_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZaHXJP7gBwGb"
   },
   "outputs": [],
   "source": [
    "train_rules_dict = build_pcfg(train_rules_counts)\n",
    "#print(train_rules_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oyzE6I_-BwGr"
   },
   "source": [
    "## Question 4\n",
    "Estimate the probability of rule $NP\\rightarrow NNP@NNP$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ky-uHUQXBwGt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated probability of 'NP -> NNP@NNP' is 0.03950843529348353\n"
     ]
    }
   ],
   "source": [
    "count_np = sum(train_rules_dict['nonterminals']['NP'].values()) + sum(train_rules_dict['terminals']['NP'].values())\n",
    "prob = train_rules_dict['nonterminals']['NP']['NNP@NNP'] / count_np\n",
    "\n",
    "print(\"Estimated probability of \\'NP -> NNP@NNP\\' is\", qMLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f8x1bPkmBwG1"
   },
   "source": [
    "## Question 5\n",
    "Find the terminal symbols in ''cnf_test[0]'' that never appeared in the PCFG we built. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OViT6-mIBwG3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The symbols that did not appear are :  ['constitutional-law']\n"
     ]
    }
   ],
   "source": [
    "#print(cnf_test[0])\n",
    "pcfg_terminals = {}\n",
    "out= []\n",
    "for i in train_rules_dict['terminals'].values():\n",
    "    #print(i)\n",
    "    for rhs in i.keys():\n",
    "        pcfg_terminals[rhs] = 1\n",
    "#print(pcfg_terminals)\n",
    "for rule in cnf_test[0].leaves():\n",
    "    if type(rule) == str:\n",
    "        n = pcfg_terminals.get(rule,0)\n",
    "        if n == 0:\n",
    "            out.append(rule)\n",
    "print(\"The symbols that did not appear are : \",out)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Jre-4bvBwG_"
   },
   "source": [
    "## Question 6\n",
    "We can use smoothing techniques to handle these cases. A simple smoothing method is as follows. We first create a new \"unknown\" terminal symbol $unk$.\n",
    "\n",
    "Next, for each original non-terminal symbol $A\\in N$, we add one new rule $A \\rightarrow unk$ to the original PCFG.\n",
    "\n",
    "The smoothed probabilities for all rules can then be estimated as:\n",
    "$$q_{smooth}(A \\rightarrow \\beta) = \\frac {count(A \\rightarrow \\beta)}{count(A)+1}$$\n",
    "$$q_{smooth}(A \\rightarrow unk) = \\frac {1}{count(A)+1}$$\n",
    "where $|V|$ is the count of unique terminal symbols.\n",
    "\n",
    "\n",
    "Implement the function **smooth_rules_prob** which returns the smoothed rule probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PA5hSj0MBwHB"
   },
   "outputs": [],
   "source": [
    "def smooth_rules_prob(rules_counts):\n",
    "    '''\n",
    "    params:\n",
    "        rules_counts: dict(dict(dict)) --- a dictionary has a form like:\n",
    "                      rules_counts = {'terminals':{'NP':{'the':1000,'an':500}, 'ADJ':{'nice':500,'good':100}},\n",
    "                                      'nonterminals':{'S':{'NP@VP':1000},'NP':{'NP@NP':540}}}\n",
    "    \n",
    "    return:\n",
    "        rules_prob: dict(dict(dict)) --- a dictionary that has a form like:\n",
    "                               rules_prob = {'terminals':{'NP':{'the':0.6,'an':0.3, '<unk>':0.1},\n",
    "                                                          'ADJ':{'nice':0.6,'good':0.3,'<unk>':0.1},\n",
    "                                                          'S':{'<unk>':0.01}}}\n",
    "                                             'nonterminals':{'S':{'NP@VP':0.99}}\n",
    "    '''\n",
    "    rules_prob = copy.deepcopy(rules_counts)\n",
    "    unk = '<unk>'\n",
    "    ### Hint: don't forget to consider nonterminal symbols that don't appear in rules_counts['terminals'].keys()\n",
    "    ### YOUR CODE HERE\n",
    "    for term in (rules_prob['terminals'].keys()):\n",
    "        #add unk\n",
    "        rules_prob['terminals'][term][unk] = 1\n",
    "        #get total counts\n",
    "        count = 0\n",
    "        count += sum(rules_prob['nonterminals'][term].values())\n",
    "        count += sum(rules_prob['terminals'][term].values())\n",
    "        # set the probability\n",
    "        for key,val in rules_prob['terminals'][term].items():\n",
    "            #print(leaf,count)\n",
    "            rules_prob['terminals'][term][key] = val/(count+1)\n",
    "    #get nonterminal symbols that dont appear in terminals\n",
    "    missing_dict = {}\n",
    "    for i in rules_prob['nonterminals'].keys():\n",
    "        #print(i)\n",
    "        if i not in rules_prob['terminals'].keys():\n",
    "            missing_dict[i] = 1\n",
    "    \n",
    "    #for each non terminal\n",
    "    for nonterm in rules_prob[\"nonterminals\"].keys():\n",
    "        count = 0\n",
    "        count += sum(rules_prob['nonterminals'][nonterm].values())\n",
    "        count += sum(rules_prob['terminals'][nonterm].values())\n",
    "        for key,val in rules_prob['nonterminals'][nonterm].items():\n",
    "            #print(leaf,count)\n",
    "            rules_prob['nonterminals'][nonterm][key] = val/(count+1)\n",
    "        if nonterm in missing_dict.keys():\n",
    "            rules_prob[\"terminals\"][nonterm][unk] = 1/(count+1)\n",
    "\n",
    "    \n",
    "        \n",
    "            \n",
    "    ### END OF YOUR CODE\n",
    "    return rules_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LfOKBjNMBwHM"
   },
   "outputs": [],
   "source": [
    "s_rules_prob = smooth_rules_prob(train_rules_dict)\n",
    "terminals.add('<unk>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AsjI5iolBwHT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1300172371337109\n",
      "0.025240088648116228\n",
      "0.03950630580310736\n",
      "{'<unk>': 5.3893829156561574e-05}\n"
     ]
    }
   ],
   "source": [
    "print(s_rules_prob['nonterminals']['S']['NP-SBJ@S|<VP-.>'])\n",
    "print(s_rules_prob['nonterminals']['S']['NP-SBJ-1@S|<VP-.>'])\n",
    "print(s_rules_prob['nonterminals']['NP']['NNP@NNP'])\n",
    "print(s_rules_prob['terminals']['NP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xnWXKQQuBwHc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11368"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(terminals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FzS8CuP6BwHk"
   },
   "source": [
    "## CKY Algorithm\n",
    "\n",
    "Similar to the Viterbi algorithm, the CKY algorithm is a dynamic-programming algorithm. Given a PCFG $G=(N, \\ \\Sigma, \\ S, \\ R, \\ q)$, we can use the CKY algorithm described in class to find the highest scoring parse tree for a sentence. \n",
    "\n",
    "First, let us complete the *CKY* function from scratch using only Python built-in functions and the Numpy package. \n",
    "\n",
    "The output should be two dictionaries $\\pi$ and $bp$, which store the optimal probability and backpointer information respectively.\n",
    "\n",
    "Given a sentence $w_0, w_1, ...,w_{n-1}$,  $\\pi(i, k, X)$, $bp(i, k, X)$ refer to the highest score and backpointer for the (partial) parse tree that has the root X (a non-terminal symbol) and covers the word span $w_i, ..., w_{k-1}$, where $0 \\le i < k \\le n$. Note that a backpointer includes both the best grammar rule chosen and the best split point.\n",
    "![tree](imgs/parse_tree.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BWp_QKhBwHm"
   },
   "source": [
    "## Question 7\n",
    "Implement **CKY** function and run the test code to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3GNbGgxsBwHq"
   },
   "outputs": [],
   "source": [
    "def CKY(sent, rules_prob):\n",
    "    '''\n",
    "    params:\n",
    "        sent: list[str] --- a list of strings\n",
    "        rules_prob: dict(dict(dict)) --- a dictionary that has a form like:\n",
    "                                           rules_prob = {'terminals':{'NP':{'the':0.6,'an':0.3, '<unk>':0.1},\n",
    "                                                                      'ADJ':{'nice':0.6,'good':0.3,'<unk>':0.1},\n",
    "                                                                      'S':{'<unk>':0.01}}}\n",
    "                                                         'nonterminals':{'S':{'NP@VP':0.99}}\n",
    "    return:\n",
    "        score: dict() --- score[(i,i+span)][root] represents the highest score for the parse (sub)tree that has the root \"root\"\n",
    "                          across words w_i, w_{i+1},..., w_{i+span-1}.\n",
    "        back: dict() --- back[(i,i+span)][root] = (split , left_child, right_child); split: int; \n",
    "                         left_child: str; right_child: str. \n",
    "    '''\n",
    "    score = defaultdict(dict)\n",
    "    back = defaultdict(dict)\n",
    "    sent_len = len(sent)\n",
    "    ### YOUR CODE HERE\n",
    "    nonterm = rules_prob[\"terminals\"].keys()\n",
    "    store = defaultdict(list)\n",
    "    for i in range(sent_len):\n",
    "        for A in nonterm:\n",
    "            if rules_prob[\"terminals\"][A].get(sent[i],0) != 0:\n",
    "                score[(i, i+1)][A] = np.log(rules_prob['terminals'][A][sent[i]])\n",
    "                back[(i, i+1)][A] = (i, sent[i], None)\n",
    "                \n",
    "    \n",
    "                \n",
    "    for span in range(2,sent_len+1):\n",
    "        for begin in range(0,sent_len+1-span):\n",
    "            end = begin+span\n",
    "            for split in range(begin+1,end):\n",
    "                for A in rules_prob['nonterminals'].keys():\n",
    "                        for BC, prob in rules_prob['nonterminals'][A].items():\n",
    "                            B, C = BC.split('@')\n",
    "                            if B in back[(begin,split)].keys() and C in back[(split,end)].keys():\n",
    "                                left = score[(begin,split)].get(B,0)\n",
    "                                right = score[(split,end)].get(C,0)\n",
    "                                cur_score = left+right+np.log(prob)\n",
    "                                if cur_score > score[(begin,end)].get(A,-999999):\n",
    "                                    score[(begin,end)][A] = cur_score\n",
    "                                    back[(begin,end)][A] = (split,B,C)\n",
    "    \n",
    "\n",
    "            \n",
    "        \n",
    "    ### END OF YOUR CODE                  \n",
    "    return score, back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dUabi0JwBwH1"
   },
   "outputs": [],
   "source": [
    "sent = cnf_train[0].leaves()\n",
    "score, back = CKY(sent, s_rules_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g07-P0eSBwH7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-117.52653989576537"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score[(0, len(sent))]['S']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GKtzvtpFBwID"
   },
   "source": [
    "## Question 8\n",
    "Implement **build_tree** function according to algorithm 2 to reconstruct theparse tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6JhyPpJUBwIE"
   },
   "outputs": [],
   "source": [
    "def build_tree(back, root,start):\n",
    "    '''\n",
    "    Build the tree recursively.\n",
    "    params:\n",
    "        back: dict() --- back[(i,i+span)][X] = (split , left_child, right_child); split:int; left_child: str; right_child: str.\n",
    "        root: tuple() --- (begin, end, nonterminal_symbol), e.g., (0, 10, 'S\n",
    "    return:\n",
    "        tree: nltk.tree.Tree\n",
    "    '''\n",
    "    begin = root[0]\n",
    "    end = root[1]\n",
    "    root_label = root[2]\n",
    "    ### YOUR CODE HERE\n",
    "    split,left,right = back[(begin,end)][root_label]\n",
    "    \n",
    "    if right == None:\n",
    "        tree = nltk.tree.Tree(root_label,[left])\n",
    "    else: \n",
    "        left_tree = build_tree(back,(begin,split,left),start)\n",
    "        right_tree = build_tree(back,(split,end,right),start)\n",
    "        tree = nltk.tree.Tree(root_label,[left_tree,right_tree])\n",
    "    \n",
    "\n",
    "    ### END OF YOUR CODE \n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pf4rrfFkBwIJ",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP-SBJ\n",
      "    (NP (NNP pierre) (NNP vinken))\n",
      "    (NP-SBJ|<,-NP-,>\n",
      "      (, ,)\n",
      "      (NP-SBJ|<NP-,>\n",
      "        (NP (CD 61) (NP|<NNS-JJ> (NNS years) (JJ old)))\n",
      "        (, ,))))\n",
      "  (S|<VP-.>\n",
      "    (VP\n",
      "      (MD will)\n",
      "      (VP\n",
      "        (VB join)\n",
      "        (VP|<NP-PP-CLR-NP-TMP>\n",
      "          (NP (DT the) (NN board))\n",
      "          (VP|<PP-CLR-NP-TMP>\n",
      "            (PP-CLR\n",
      "              (IN as)\n",
      "              (NP\n",
      "                (DT a)\n",
      "                (NP|<JJ-NN> (JJ nonexecutive) (NN director))))\n",
      "            (NP-TMP (NNP nov.) (CD 29))))))\n",
      "    (. .)))\n"
     ]
    }
   ],
   "source": [
    "build_tree(back, (0, len(sent), 'S'), nonterminals).pprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BREjaTD0BwIY"
   },
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ylVH27EyBwIa"
   },
   "outputs": [],
   "source": [
    "def set_leave_index(tree):\n",
    "    '''\n",
    "    Label the leaves of the tree with indexes\n",
    "    Arg:\n",
    "        tree: original tree, nltk.tree.Tree\n",
    "    Return:\n",
    "        tree: preprocessed tree, nltk.tree.Tree\n",
    "    '''\n",
    "    for idx, _ in enumerate(tree.leaves()):\n",
    "        tree_location = tree.leaf_treeposition(idx)\n",
    "        non_terminal = tree[tree_location[:-1]]\n",
    "        non_terminal[0] = non_terminal[0] + \"_\" + str(idx)\n",
    "    return tree\n",
    "\n",
    "def get_nonterminal_bracket(tree):\n",
    "    '''\n",
    "    Obtain the constituent brackets of a tree\n",
    "    Arg:\n",
    "        tree: tree, nltk.tree.Tree\n",
    "    Return:\n",
    "        nonterminal_brackets: constituent brackets, set\n",
    "    '''\n",
    "    nonterminal_brackets = set()\n",
    "    for tr in tree.subtrees():\n",
    "        label = tr.label()\n",
    "        #print(tr.leaves())\n",
    "        if len(tr.leaves()) == 0:\n",
    "            continue\n",
    "        start = tr.leaves()[0].split('_')[-1]\n",
    "        end = tr.leaves()[-1].split('_')[-1]\n",
    "        if start != end:\n",
    "            nonterminal_brackets.add(label+'-('+start+':'+end+')')\n",
    "    return nonterminal_brackets\n",
    "\n",
    "def word2lower(w, terminals):\n",
    "    '''\n",
    "    Map an unknow word to \"unk\"\n",
    "    '''\n",
    "    return w.lower() if w in terminals else '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eCJhoQjQBwIl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Test Tree: 1\n",
      "Constituent number in the predicted tree: 20\n",
      "Constituent number in the gold tree: 20\n",
      "Correct constituent number: 14\n",
      "####################\n",
      "Test Tree: 2\n",
      "Constituent number in the predicted tree: 54\n",
      "Constituent number in the gold tree: 54\n",
      "Correct constituent number: 27\n",
      "####################\n",
      "Test Tree: 3\n",
      "Constituent number in the predicted tree: 30\n",
      "Constituent number in the gold tree: 30\n",
      "Correct constituent number: 23\n",
      "####################\n",
      "Test Tree: 4\n",
      "Constituent number in the predicted tree: 17\n",
      "Constituent number in the gold tree: 17\n",
      "Correct constituent number: 16\n",
      "####################\n",
      "Test Tree: 5\n",
      "Constituent number in the predicted tree: 32\n",
      "Constituent number in the gold tree: 32\n",
      "Correct constituent number: 26\n",
      "####################\n",
      "Test Tree: 6\n",
      "Constituent number in the predicted tree: 40\n",
      "Constituent number in the gold tree: 40\n",
      "Correct constituent number: 18\n",
      "####################\n",
      "Test Tree: 7\n",
      "Constituent number in the predicted tree: 22\n",
      "Constituent number in the gold tree: 22\n",
      "Correct constituent number: 7\n",
      "####################\n",
      "Test Tree: 8\n",
      "Constituent number in the predicted tree: 18\n",
      "Constituent number in the gold tree: 18\n",
      "Correct constituent number: 6\n",
      "####################\n",
      "Test Tree: 9\n",
      "Constituent number in the predicted tree: 28\n",
      "Constituent number in the gold tree: 28\n",
      "Correct constituent number: 16\n",
      "####################\n",
      "Test Tree: 10\n",
      "Constituent number in the predicted tree: 40\n",
      "Constituent number in the gold tree: 40\n",
      "Correct constituent number: 8\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "pred_count = 0\n",
    "gold_count = 0\n",
    "for i, t in enumerate(cnf_test):\n",
    "    #Protect the original tree \n",
    "    t = copy.deepcopy(t)\n",
    "    sent = t.leaves()  \n",
    "    #Map the unknow words to \"unk\"\n",
    "    sent = [word2lower(w.lower(), terminals) for w in sent]\n",
    "    \n",
    "    #CKY algorithm\n",
    "    score, back = CKY(sent, s_rules_prob)\n",
    "    candidate_tree = build_tree(back, (0, len(sent), 'S'), nonterminals)\n",
    "    \n",
    "    #Extract constituents from the gold tree and predicted tree\n",
    "    pred_tree = set_leave_index(candidate_tree)\n",
    "    pred_brackets = get_nonterminal_bracket(pred_tree)\n",
    "    \n",
    "    #Count correct constituents\n",
    "    pred_count += len(pred_brackets)\n",
    "    gold_tree = set_leave_index(t)\n",
    "    gold_brackets = get_nonterminal_bracket(gold_tree)\n",
    "    gold_count += len(gold_brackets)\n",
    "    current_correct_num = len(pred_brackets.intersection(gold_brackets))\n",
    "    correct_count += current_correct_num\n",
    "    \n",
    "    print('#'*20)\n",
    "    print('Test Tree:', i+1)\n",
    "    print('Constituent number in the predicted tree:', len(pred_brackets))\n",
    "    print('Constituent number in the gold tree:', len(gold_brackets))\n",
    "    print('Correct constituent number:', current_correct_num)\n",
    "\n",
    "recall = correct_count/gold_count\n",
    "precision = correct_count/pred_count\n",
    "f1 = 2*recall*precision/(recall+precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6_XBc6-BwIy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall precision: 0.535, recall: 0.535, f1: 0.535\n"
     ]
    }
   ],
   "source": [
    "print('Overall precision: {:.3f}, recall: {:.3f}, f1: {:.3f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcVa_8gtBwJD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall precision: 0.535, recall: 0.535, f1: 0.535\n"
     ]
    }
   ],
   "source": [
    "print('Overall precision: {:.3f}, recall: {:.3f}, f1: {:.3f}'.format(precision, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6MSULjTYBwJI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912.660706281662\n"
     ]
    }
   ],
   "source": [
    "et=time.time()\n",
    "print(et - st)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "homework2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
